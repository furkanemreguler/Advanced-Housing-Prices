# House Prices: Advanced Regression Techniques

![Kaggle](https://img.shields.io/badge/Kaggle-Advanced%20Regression%20Techniques-blue) ![License](https://img.shields.io/badge/License-MIT-green)

## ğŸ“‹ Table of Contents

- [Project Overview](#project-overview)  
- [Dataset](#dataset)  
- [Directory Structure](#directory-structure)  
- [Setup & Installation](#setup--installation)  
- [Exploratory Data Analysis](#exploratory-data-analysis)  
- [Feature Engineering & Preprocessing](#feature-engineering--preprocessing)  
- [Modeling](#modeling)  
- [Evaluation](#evaluation)  
- [Submission](#submission)  
- [Results & Leaderboard](#results--leaderboard)  
- [Next Steps](#next-steps)  
- [License](#license)  

---

## ğŸš€ Project Overview

Predict the final sale price of residential homes in Ames, Iowa, using a variety of regression techniques. This notebookâ€driven pipeline walks through:

1. **Data loading & cleaning**  
2. **Exploratory Data Analysis (EDA)**  
3. **Feature engineering & handling missing values**  
4. **Model training (Linear Regression, Random Forest, XGBoost, â€¦)**  
5. **Hyperparameter tuning & stacking**  
6. **Submission file generation**  

---

## ğŸ“‚ Dataset

All files live in the `data/` folder:

- `train.csv`Â â€“ 1,460 observations with SalePrice  
- `test.csv`Â â€“ 1,459 observations, no SalePrice  
- `data_description.txt`Â â€“ detailed feature descriptions  
- `sample_submission.csv`Â â€“ example submission format  

Source: [Kaggle House Prices Competition](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques)

---

## ğŸ“ Directory Structure

Advanced-Housing-Prices/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ train.csv
â”‚ â”œâ”€â”€ test.csv
â”‚ â”œâ”€â”€ sample_submission.csv
â”‚ â””â”€â”€ data_description.txt
â”œâ”€â”€ model.ipynb
â”œâ”€â”€ requirements.txt
â””â”€â”€ submission.csv


---

## ğŸš€ Getting Started

1. **Clone this repo**  
   git clone https://github.com/yourusername/Advanced-Housing-Prices.git
   cd Advanced-Housing-Prices
   
2. **Create & activate a virtual environment**
  python3 -m venv .venv
  source .venv/bin/activate

3. **Install dependencies**
  pip install -r requirements.txt

4. **Launch Jupyter Notebook**
  jupyter notebook model.ipynb

## model.ipynb Workflow

1. **Data loading**  
   - Read `train.csv` and `test.csv` from `/data`  
   - Inspect feature distributions & missingness  

2. **Exploratory Data Analysis (EDA)**  
   - Target distribution (`SalePrice`)  
   - Correlations, outliers, key plots  

3. **Preprocessing & Feature Engineering**  
   - Drop highâ€‘missing columns  
   - Impute numerics (median) & categoricals (mode)  
   - Logâ€transform skewed features  
   - Oneâ€‘hot encode / labelâ€‘encode  

4. **Model Training & Evaluation**  
   - Train/Test split on train set  
   - Compare models:  
     - Linear Regression  
     - Random Forest  
     - XGBoost (`XGBRegressor`)  
   - Use crossâ€‘validation RMSE  

5. **Generate Submission**  
   - Predict on `test.csv`  
   - Write to `submission.csv`  

---

## âš™ï¸ Dependencies

All required libraries are pinned in `requirements.txt`. Key packages include:

- `pandas`, `numpy`  
- `scikit-learn`  
- `xgboost`  
- `matplotlib`, `seaborn`  
- `jupyter`

To add new packages, install via:
```bash
pip install <package_name>
pip freeze > requirements.txt
'''

   
